{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Edge List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('out.tsv', delim_whitespace=True)\n",
    "\n",
    "#add prefixes to distinguish escort and buyer nodes\n",
    "df['FromNode'] = df['FromNode'].apply(lambda x: \"{}{}\".format('Buyer', x))\n",
    "df['ToNode'] = df['ToNode'].apply(lambda x: \"{}{}\".format('Escort', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007    14604\n",
       "2006    12035\n",
       "2008    11989\n",
       "2005     8036\n",
       "2004     3526\n",
       "2003      434\n",
       "2002        8\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert time\n",
    "year = []; month = []; day= []\n",
    "i = 0\n",
    "for t in df['time']:\n",
    "    t = int(t)\n",
    "    if t < 0: \n",
    "        time.append(np.nan)\n",
    "        print(datetime.utcfromtimestamp(-t).year)\n",
    "        i+=1\n",
    "    else: \n",
    "        time = datetime.utcfromtimestamp(t)\n",
    "        year.append(time.year)\n",
    "        month.append(time.month)\n",
    "        day.append(time.day)\n",
    "        \n",
    "df['year'] = year\n",
    "df['month'] = month\n",
    "df['day'] = day\n",
    "\n",
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataframe into train and test period\n",
    "train_df = df.loc[df['year'] > 2005]\n",
    "train_df = df.loc[df['year'] < 2008]\n",
    "test_df = df.loc[df['year'] == 2008]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change ratings to occurances with average rating\n",
    "edges_df = train_df.groupby(['FromNode', 'ToNode'],as_index=False).mean()[['FromNode', 'ToNode','weight']]\n",
    "\n",
    "edges_df['Occurences'] = train_df.groupby(['FromNode', 'ToNode'],as_index=False).count()['weight']\n",
    "\n",
    "edges_df['year'] = df.groupby(['FromNode', 'ToNode'],as_index=False).min()['year']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read labelled data\n",
    "How the labelled data is gathered is mentioned in some cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges = pd.read_csv('safety.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromNode</th>\n",
       "      <th>ToNode</th>\n",
       "      <th>y</th>\n",
       "      <th>shortest distance</th>\n",
       "      <th>Sum of Papers</th>\n",
       "      <th>Sum of Neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buyer1002</td>\n",
       "      <td>Escort1426</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buyer1002</td>\n",
       "      <td>Escort4403</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buyer1007</td>\n",
       "      <td>Escort3873</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buyer1010</td>\n",
       "      <td>Escort5000</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buyer1013</td>\n",
       "      <td>Escort5178</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FromNode      ToNode     y  shortest distance  Sum of Papers  Sum of Neighbours\n",
       "0  Buyer1002  Escort1426  True                3.0            160                103\n",
       "1  Buyer1002  Escort4403  True                3.0             18                 18\n",
       "2  Buyer1007  Escort3873  True                5.0             29                 17\n",
       "3  Buyer1010  Escort5000  True                3.0             22                 22\n",
       "4  Buyer1013  Escort5178  True                7.0              9                  8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edges.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "test_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS HOW TEST EDGES WAS CREATED \n",
    "\n",
    "from networkx.algorithms import bipartite\n",
    "TG = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "TG.add_nodes_from(edges['FromNode'].unique().tolist(), bipartite=0)\n",
    "TG.add_nodes_from(edges['ToNode'].unique().tolist(),  bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "r = edges[['FromNode', 'ToNode']].to_records(index=False)\n",
    "TG.add_edges_from(list(r)) \n",
    "\n",
    "buyer_nodes = {n for n, d in TG.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "escort_nodes = set(TG) - buyer_nodes\n",
    "\n",
    "f = []; t = []\n",
    "i = 0\n",
    "for node in buyer_nodes: \n",
    "    i+=1\n",
    "    if i %1000 == 0:\n",
    "        print(i, len(buyer_nodes))\n",
    "    no_neighbours = nx.non_neighbors(TG, node)\n",
    "    for n in no_neighbours:\n",
    "        if n in escort_nodes:\n",
    "            f.append(node)\n",
    "            t.append(n)\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "temp['FromNode'] = f\n",
    "temp['ToNode'] = t\n",
    "temp['y'] = False\n",
    "\n",
    "test_edges = pd.concat([test_edges,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make graph at present phase\n",
    "g = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "g.add_nodes_from(edges_df['FromNode'].unique().tolist(), bipartite=0)\n",
    "g.add_nodes_from(edges_df['ToNode'].unique().tolist(),  bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "r = edges_df[['FromNode', 'ToNode']].to_records(index=False)\n",
    "g.add_edges_from(list(r)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.404800234157764"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buyer_nodes = {n for n, d in g.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "escort_nodes = set(g) - buyer_nodes\n",
    "\n",
    "degreees = [t[1] for t in g.degree]\n",
    "np.mean(degreees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Buyers 8386 Unique escorts 5280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Unique Buyers\", len(edges_df['FromNode'].unique()), 'Unique escorts', len(edges_df['ToNode'].unique()))\n",
    "unique_nodes = edges_df['FromNode'].unique().tolist()\n",
    "unique_nodes.extend(edges_df['ToNode'].unique())\n",
    "\n",
    "\n",
    "nodes = pd.DataFrame()\n",
    "nodes['Node'] = list(unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DONE \n",
    "# sum of papers \n",
    "sum_papers = []; sum_papers2 = []\n",
    "for i, row in nodes.iterrows():\n",
    "    #get all edges in which row[node] is in\n",
    "    temp = edges_df[(edges_df['FromNode'] == row['Node']) | (edges_df['ToNode'] == row['Node'])]\n",
    "    sum_papers.append(sum(temp['Occurences']))\n",
    "    if sum(temp['Occurences']) == 0: \n",
    "        sum_papers2.append(0)\n",
    "    else:\n",
    "        sum_papers2.append(sum(temp['Occurences'])/temp.shape[0])#only if weights differ from one\n",
    "\n",
    "#%%\n",
    "\n",
    "nodes['Sum of Papers'] = sum_papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "### SUm of Neighbours\n",
    "from networkx.classes.function import neighbors\n",
    "temp = nx.Graph(g)\n",
    "sum_neighbours = []\n",
    "\n",
    "for i, row in nodes.iterrows():\n",
    "    sum_neighbours.append(temp.degree(row['Node'])) #len([n for n in temp.neighbors(row['Node'])])) # degree\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "nodes['Sum of Neighbours'] = sum_neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "### WEIGHTED NEIGHBOURS\n",
    "\n",
    "from networkx.classes.function import neighbors\n",
    "temp = nx.Graph(g)\n",
    "sum_neighbours = []\n",
    "\n",
    "for i, row in nodes.iterrows():\n",
    "    sum_neighbours.append(temp.degree(row['Node'],weight = 'Occurences')) #len([n for n in temp.neighbors(row['Node'])])) # degree\n",
    "nodes['Weighted Sum of Neighbours'] = sum_neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE\n",
    "### SHortest Distance\n",
    "shortest_distance = [] \n",
    "j = 0\n",
    "start = True\n",
    "for i, row in test_edges.iterrows():\n",
    "    if j %1000000 == 0: \n",
    "        print (j, test_edges.shape, 'index', i, 'shortest distance', len(shortest_distance))\n",
    "    j+=1\n",
    "    try:\n",
    "        X = nx.shortest_path_length(g, row['FromNode'], row['ToNode'])\n",
    "        shortest_distance.append(X)\n",
    "    except nx.NetworkXNoPath:\n",
    "        shortest_distance.append(np.inf)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "len(shortest_distance)\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "test_edges['shortest distance'] = shortest_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "papers_dict = pd.Series(nodes['Sum of Papers'].values,index=nodes['Node']).to_dict()\n",
    "\n",
    "#%%\n",
    "\n",
    "neighbours_dict = pd.Series(nodes['Sum of Neighbours'].values,index=nodes['Node']).to_dict()\n",
    "\n",
    "#%%\n",
    "\n",
    "papers = []; neighbours = [] \n",
    "j = 0\n",
    "for i, row in test_edges.iterrows():\n",
    "    j+=1\n",
    "    if j %1000000 == 0: \n",
    "        print (j, test_edges.shape, 'index', i, 'length', len(papers))\n",
    "    papers.append(papers_dict[row['FromNode']] + papers_dict[row['ToNode']])\n",
    "    neighbours.append(neighbours_dict[row['FromNode']] + neighbours_dict[row['ToNode']])\n",
    "\n",
    "#%%\n",
    "\n",
    "test_edges['Sum of Papers'] = papers\n",
    "test_edges['Sum of Neighbours'] = neighbours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "import random\n",
    "random.seed(42)\n",
    "neg_indices = test_edges.loc[test_edges['y']== False].index.to_list()\n",
    "neg_sample = random.sample(neg_indices, 60)\n",
    "test_edges_sample = test_edges.loc[neg_sample]\n",
    "test_edges_sample = pd.concat([test_edges_sample, test_edges.loc[test_edges['y']== True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neighbourhood sample\n",
    "test_edges_neighbourhood = test_edges.loc[test_edges['shortest distance'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def dummy(x):\n",
    "    avg_acc = []; avg_precision =[]; avg_recall = []; avg_f1 = []; avg_auc = []\n",
    "    for seed in [0,1,2,3,4]:\n",
    "        acc =[]; precision = []; recall = []; f1 = []; auc = []\n",
    "        cv = model_selection.StratifiedKFold(n_splits=5, shuffle = True, random_state = seed)\n",
    "        for train_index, test_index in cv.split(x, x['y']):\n",
    "            x_tr, x_te = x.iloc[train_index], x.iloc[test_index]\n",
    "            if x_tr.loc[x_tr['y']==1,'y'].shape[0] <=  x_tr.loc[x_tr['y']==0,'y'].shape[0]:\n",
    "                majority_class = 0\n",
    "            else: \n",
    "                majority_class = 1\n",
    "            print('majority class: ', majority_class)\n",
    "            y_pred = [majority_class for i in range(len(x_te['y']))]\n",
    "            y_te = x_te['y'].tolist()\n",
    "\n",
    "\n",
    "            acc.append(metrics.accuracy_score(y_te, y_pred))\n",
    "            precision.append(metrics.precision_score(y_te, y_pred))\n",
    "            recall.append(metrics.recall_score(y_te, y_pred))\n",
    "            f1.append(metrics.f1_score(y_te, y_pred))\n",
    "            auc.append(metrics.roc_auc_score(y_te, y_pred))\n",
    "        avg_acc.append(np.mean(acc))\n",
    "        avg_precision.append(np.mean(precision))\n",
    "        avg_recall.append(np.mean(recall))\n",
    "        avg_f1.append(np.mean(f1))\n",
    "        avg_auc.append(np.mean(auc))\n",
    "    print('acc', avg_acc, np.mean(avg_acc))\n",
    "    print('precision',avg_precision,  np.mean(avg_precision))\n",
    "    print('recall',avg_recall, np.mean(avg_recall))\n",
    "    print('f1', avg_f1,  np.mean(avg_f1))\n",
    "    print('AUC',avg_auc, np.mean(avg_auc))\n",
    "\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc [0.9999326974956754, 0.9999326974956754, 0.9999326974956754, 0.9999326974956754, 0.9999326974956754] 0.9999326974956754\n",
      "precision [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "recall [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "f1 [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "AUC [0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n"
     ]
    }
   ],
   "source": [
    "dummy(test_edges[['FromNode','ToNode', 'y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x, threshold = 0.5, jaccard = None, verbose = True):\n",
    "    avg_acc = []; avg_precision =[]; avg_recall = []; avg_f1 = []; avg_auc = []\n",
    "\n",
    "    for seed in [0,1,2,3,4]:\n",
    "        #print('seed', seed)\n",
    "        acc =[]; precision = []; recall = []; f1 = []; auc = []\n",
    "        cv = model_selection.StratifiedKFold(n_splits=5, shuffle = True, random_state = seed)\n",
    "        for train_index, test_index in cv.split(x,x['y']):\n",
    "            x_tr, x_te = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_pred = []\n",
    "            y_te = []\n",
    "            for i, row in x_te.iterrows(): \n",
    "                if (row['FromNode'], row['ToNode']) in jaccard.keys():\n",
    "                    key = (row['FromNode'], row['ToNode'])\n",
    "                else: \n",
    "                    key = (row['ToNode'], row['FromNode'])\n",
    "                if jaccard[key] < threshold:\n",
    "                    y_pred.append(0)\n",
    "                else: \n",
    "                    y_pred.append(1)\n",
    "                y_te.append(row['y'])\n",
    "            acc.append(metrics.accuracy_score(y_te, y_pred))\n",
    "            precision.append(metrics.precision_score(y_te, y_pred))\n",
    "            recall.append(metrics.recall_score(y_te, y_pred))\n",
    "            f1.append(metrics.f1_score(y_te, y_pred))\n",
    "            auc.append(metrics.roc_auc_score(y_te, y_pred))\n",
    "        avg_acc.append(np.mean(acc))\n",
    "        avg_precision.append(np.mean(precision))\n",
    "        avg_recall.append(np.mean(recall))\n",
    "        avg_f1.append(np.mean(f1))\n",
    "        avg_auc.append(np.mean(auc))\n",
    "    if verbose:\n",
    "        print('acc', avg_acc, np.mean(avg_acc))\n",
    "        print('precision',avg_precision,  np.mean(avg_precision))\n",
    "        print('recall',avg_recall, np.mean(avg_recall))\n",
    "        print('f1', avg_f1,  np.mean(avg_f1))\n",
    "        print('AUC',avg_auc, np.mean(avg_auc))\n",
    "    else:\n",
    "        print('acc',np.mean(avg_acc))\n",
    "        print('precision',np.mean(avg_precision))\n",
    "        print('recall',np.mean(avg_recall))\n",
    "        print('f1', np.mean(avg_f1))\n",
    "        print('AUC',np.mean(avg_auc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges['jtuple'] = list(zip(test_edges.FromNode, test_edges.ToNode))\n",
    "jaccard_similarity = list(nx.jaccard_coefficient(g, test_edges['jtuple'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_dict= {}\n",
    "for j in list(jaccard_similarity):\n",
    "    jaccard_dict[(j[0], j[1])] = j[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc [0.9999326974956754, 0.9999326974956754, 0.9999326974956754, 0.9999326974956754, 0.9999326974956754] 0.9999326974956754\n",
      "precision [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "recall [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "f1 [0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "AUC [0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n"
     ]
    }
   ],
   "source": [
    "jaccard(test_edges[['FromNode','ToNode', 'y']],jaccard= jaccard_dict,threshold = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node2Vec\n",
    "Implementation from https://stellargraph.readthedocs.io/en/stable/demos/link-prediction/node2vec-link-prediction.html. This code is merely altered for my purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stellargraph import StellarGraph, datasets\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def node2vec_embedding(graph, name):\n",
    "    p = 1.0\n",
    "    q = 1.0\n",
    "    dimensions = 128\n",
    "    num_walks = 10\n",
    "    walk_length = 80\n",
    "    window_size = 10\n",
    "    num_iter = 1\n",
    "    workers = multiprocessing.cpu_count()\n",
    "    rw = BiasedRandomWalk(graph)\n",
    "    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length, p=p, q=q)\n",
    "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
    "\n",
    "    model = Word2Vec(\n",
    "        walks,\n",
    "        size=dimensions,\n",
    "        window=window_size,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=workers,\n",
    "        iter=num_iter,\n",
    "    )\n",
    "\n",
    "    def get_embedding(u):\n",
    "        return model.wv[u]\n",
    "\n",
    "    return get_embedding\n",
    "\n",
    "\n",
    "# 1. link embeddings\n",
    "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
    "    return [\n",
    "        binary_operator(transform_node(src), transform_node(dst))\n",
    "        for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "\n",
    "# 2. training classifier\n",
    "def train_link_prediction_model(\n",
    "    link_examples, link_labels, get_embedding, binary_operator, seed\n",
    "):\n",
    "    clf = link_prediction_classifier(seed)\n",
    "    link_features = link_examples_to_features(\n",
    "        link_examples, get_embedding, binary_operator\n",
    "    )\n",
    "    clf.fit(link_features, link_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def link_prediction_classifier(seed, max_iter=2000):\n",
    "    lr_clf = LogisticRegression(C=10, max_iter=max_iter, random_state = seed)\n",
    "    #LogisticRegressionCV(Cs=10, cv=3, scoring=\"roc_auc\", max_iter=max_iter, random_state = seed)\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
    "\n",
    "\n",
    "# 3. and 4. evaluate classifier\n",
    "def evaluate_link_prediction_model(\n",
    "    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n",
    "):\n",
    "    link_features_test = link_examples_to_features(\n",
    "        link_examples_test, get_embedding, binary_operator\n",
    "    )\n",
    "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
    "    return score\n",
    "\n",
    "\n",
    "def evaluate_roc_auc(clf, link_features, link_labels):\n",
    "    predicted = clf.predict(link_features)\n",
    "    return metrics.accuracy_score(link_labels, predicted), metrics.precision_score(link_labels, predicted), metrics.recall_score(link_labels, predicted),metrics.f1_score(link_labels, predicted), metrics.roc_auc_score(link_labels, predicted)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def operator_hadamard(u, v):\n",
    "    return u * v\n",
    "\n",
    "\n",
    "def operator_l1(u, v):\n",
    "    return np.abs(u - v)\n",
    "\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def operator_avg(u, v):\n",
    "    return (u + v) / 2.0\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def node2vec(x, seed = 42): \n",
    "    # get training\n",
    "    edges = edges_df[['FromNode', 'ToNode', 'Occurences']]\n",
    "    edges = edges.rename(columns = {'FromNode':'source', 'ToNode':'target', 'Occurences': 'weight'})\n",
    "    train_graph = StellarGraph(edges=edges)\n",
    "    print(train_graph.info())\n",
    "    \n",
    "    # test graph: ever needed? \n",
    "    #edges = edges_df[['Node1', 'Node2', 'Occurances']]\n",
    "    #edges = edges.rename(columns = {'Node1':'source', 'Node2':'target', 'Occurances': 'weight'})\n",
    "    #test_graph = StellarGraph(edges=edges)\n",
    "    #print(test_graph.info())\n",
    "    \n",
    "\n",
    "\n",
    "    embedding_train = node2vec_embedding(train_graph, \"train\")\n",
    "    \n",
    "    \n",
    "    y = test_edges['y']\n",
    "    \n",
    "    \n",
    "    \n",
    "           \n",
    "    for binary_operator in  [operator_hadamard, operator_l1, operator_l2, operator_avg]: \n",
    "        avg_acc = []; avg_precision =[]; avg_recall = []; avg_f1 = []; avg_auc = []\n",
    "        for seed in [0]:#,1,2,3,4]:\n",
    "            cv = model_selection.KFold(n_splits=2, shuffle = True, random_state = seed) \n",
    "            for train_index, test_index in cv.split(x):\n",
    "                acc =[]; precision =[]; recall = []; f1 =[]; auc = []\n",
    "                index = random.sample(x.index.to_list(), int(len(x)/5))\n",
    "                y_tr = y.iloc[train_index].to_numpy()\n",
    "                x_tr = x.iloc[train_index].to_numpy()\n",
    "                y_te = y.iloc[test_index].to_numpy()\n",
    "                x_te = x.iloc[test_index].to_numpy()\n",
    "\n",
    "                clf = train_link_prediction_model(x_tr,y_tr, embedding_train, binary_operator,seed)\n",
    "                a, p, r, f, ac = evaluate_link_prediction_model(clf,x_te,y_te,embedding_train,binary_operator)\n",
    "\n",
    "                acc.append(a)\n",
    "                precision.append(p)\n",
    "                recall.append(r)\n",
    "                f1.append(f)\n",
    "                auc.append(ac)\n",
    "            avg_acc.append(np.mean(acc))\n",
    "            avg_precision.append(np.mean(precision))\n",
    "            avg_recall.append(np.mean(recall))\n",
    "            avg_f1.append(np.mean(f1))\n",
    "            avg_auc.append(np.mean(auc))\n",
    "            \n",
    "        print('---')\n",
    "        print(binary_operator.__name__)\n",
    "        print('acc', avg_acc, np.mean(avg_acc))\n",
    "        print('precision',avg_precision,  np.mean(avg_precision))\n",
    "        print('recall',avg_recall, np.mean(avg_recall))\n",
    "        print('f1', avg_f1,  np.mean(avg_f1))\n",
    "        print('AUC',avg_auc, np.mean(avg_auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 13666, Edges: 30098\n",
      "\n",
      " Node types:\n",
      "  default: [13666]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [30098]\n",
      "        Weights: range=[1, 36], mean=1.28391, std=1.18903\n",
      "        Features: none\n",
      "Number of random walks for 'train': 136660\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.1 GiB for an array with shape (22123991, 128) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-233698f1335b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnode2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FromNode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ToNode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-758e0e2fcee3>\u001b[0m in \u001b[0;36mnode2vec\u001b[1;34m(x, seed)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mx_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_link_prediction_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_operator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_link_prediction_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary_operator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-758e0e2fcee3>\u001b[0m in \u001b[0;36mtrain_link_prediction_model\u001b[1;34m(link_examples, link_labels, get_embedding, binary_operator, seed)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mlink_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_operator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     )\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_seen_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                     _incremental_mean_and_var(X, self.mean_, self.var_,\n\u001b[0m\u001b[0;32m    763\u001b[0m                                               self.n_samples_seen_)\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;31m# updated = the aggregated stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[0mlast_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_mean\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlast_sample_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m     \u001b[0mnew_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[0mnew_sample_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnansum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36mnansum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \"\"\"\n\u001b[1;32m--> 649\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_replace_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36m_replace_nan\u001b[1;34m(a, val)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 21.1 GiB for an array with shape (22123991, 128) and data type float64"
     ]
    }
   ],
   "source": [
    "node2vec(test_edges[['FromNode', 'ToNode']], 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#%%\n",
    "\n",
    "def bagging(x,y):\n",
    "    avg_acc = []; avg_precision =[]; avg_recall = []; avg_f1 = []; avg_auc = []\n",
    "    \n",
    "    x = x.replace(np.inf, -1)\n",
    "    for seed in [0,1,2,3,4]:\n",
    "        print(seed)\n",
    "        acc =[]; precision = []; recall = []; f1 = []; auc = []\n",
    "        cv = model_selection.StratifiedKFold(n_splits=5, shuffle = True, random_state = seed)\n",
    "        clf =BaggingClassifier( n_estimators=10, random_state=42)\n",
    "        for train_index, test_index in cv.split(x,y):\n",
    "            x_tr, x_te = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_tr, y_te = y.iloc[train_index], y.iloc[test_index]\n",
    "            clf.fit(x_tr, y_tr)\n",
    "            y_pred = clf.predict(x_te)\n",
    "            acc.append(metrics.accuracy_score(y_te, y_pred))\n",
    "            precision.append(metrics.precision_score(y_te, y_pred))\n",
    "            recall.append(metrics.recall_score(y_te, y_pred))\n",
    "            f1.append(metrics.f1_score(y_te, y_pred))\n",
    "            auc.append(metrics.roc_auc_score(y_te, y_pred))\n",
    "            \n",
    "            print(acc)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(f1)\n",
    "            print(auc)\n",
    "        avg_acc.append(np.mean(acc))\n",
    "        avg_precision.append(np.mean(precision))\n",
    "        avg_recall.append(np.mean(recall))\n",
    "        avg_f1.append(np.mean(f1))\n",
    "        avg_auc.append(np.mean(auc))\n",
    "        \n",
    "    print('acc', avg_acc, np.mean(avg_acc))\n",
    "    print('precision',avg_precision,  np.mean(avg_precision))\n",
    "    print('recall',avg_recall, np.mean(avg_recall))\n",
    "    print('f1', avg_f1,  np.mean(avg_f1))\n",
    "    print('AUC',avg_auc, np.mean(avg_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.9999310703074954]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.49999920895025324]\n",
      "[0.9999310703074954, 0.9999314093059831]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.49999920895025324, 0.49999937846091325]\n",
      "[0.9999310703074954, 0.9999314093059831, 0.9999317482967585]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.49999920895025324, 0.49999937846091325, 0.4999995479715222]\n",
      "[0.9999310703074954, 0.9999314093059831, 0.9999317482967585, 0.9999316352972497]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.49999920895025324, 0.49999937846091325, 0.4999995479715222, 0.49999943496446664]\n",
      "[0.9999310703074954, 0.9999314093059831, 0.9999317482967585, 0.9999316352972497, 0.9999322002947931]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.49999920895025324, 0.49999937846091325, 0.4999995479715222, 0.49999943496446664, 0.4999997174822333]\n",
      "acc [0.999931612700456] 0.999931612700456\n",
      "precision [0.0] 0.0\n",
      "recall [0.0] 0.0\n",
      "f1 [0.0] 0.0\n",
      "AUC [0.49999945756587777] 0.49999945756587777\n"
     ]
    }
   ],
   "source": [
    "x = test_edges[['Sum of Neighbours', 'Sum of Papers', 'shortest distance']]\n",
    "y = test_edges['y']\n",
    "\n",
    "bagging(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "#%%\n",
    "\n",
    "def svd(x):\n",
    "    avg_acc = []; avg_precision =[]; avg_recall = []; avg_f1 = []; avg_auc = []\n",
    "    \n",
    "    \n",
    "    algo = SVD()\n",
    "    reader = Reader(rating_scale=(0,1))\n",
    "    for seed in [0]:\n",
    "        acc =[]; precision = []; recall = []; f1 = []; auc = []\n",
    "        cv = model_selection.KFold(n_splits=5, shuffle = True, random_state = seed)\n",
    "        accuracy = []\n",
    "        # define a cross-validation iterator\n",
    "        #kf = KFold(n_splits=5, random_state =42)\n",
    "        cv = model_selection.StratifiedKFold(n_splits=5, shuffle = True, random_state = seed)\n",
    "        algo = SVD()\n",
    "        for train_index, test_index in cv.split(x,x['y']):\n",
    "        # The columns must correspond to user id, item id and ratings (in that order).\n",
    "            x_tr, x_te = x.iloc[train_index], x.iloc[test_index]\n",
    "            trainset = Dataset.load_from_df(x_tr, reader)\n",
    "            testset = Dataset.load_from_df(x_te, reader)\n",
    "        #for trainset, testset in kf.split(data):\n",
    "\n",
    "            # train and test algorithm.\n",
    "            trainset = trainset.build_full_trainset()\n",
    "            algo.fit(trainset)\n",
    "            testset = testset.build_full_trainset().build_testset()\n",
    "            predictions = algo.test(testset)\n",
    "            y_te = []; y_pred = []\n",
    "            for p in range(len(predictions)):\n",
    "                y_te.append(testset[p][2])\n",
    "                if predictions[p].est <= 0.5:\n",
    "                    y_pred.append(0)\n",
    "                else:\n",
    "                    y_pred.append(1)\n",
    "            acc.append(metrics.accuracy_score(y_te, y_pred))\n",
    "            precision.append(metrics.precision_score(y_te, y_pred))\n",
    "            recall.append(metrics.recall_score(y_te, y_pred))\n",
    "            f1.append(metrics.f1_score(y_te, y_pred))\n",
    "            auc.append(metrics.roc_auc_score(y_te, y_pred))\n",
    "        avg_acc.append(np.mean(acc))\n",
    "        avg_precision.append(np.mean(precision))\n",
    "        avg_recall.append(np.mean(recall))\n",
    "        avg_f1.append(np.mean(f1))\n",
    "        avg_auc.append(np.mean(auc))\n",
    "        \n",
    "    print('acc', avg_acc, np.mean(avg_acc))\n",
    "    print('precision',avg_precision,  np.mean(avg_precision))\n",
    "    print('recall',avg_recall, np.mean(avg_recall))\n",
    "    print('f1', avg_f1,  np.mean(avg_f1))\n",
    "    print('AUC',avg_auc, np.mean(avg_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thale\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc [0.9999326974956754] 0.9999326974956754\n",
      "precision [0.0] 0.0\n",
      "recall [0.0] 0.0\n",
      "f1 [0.0] 0.0\n",
      "AUC [0.5] 0.5\n"
     ]
    }
   ],
   "source": [
    "svd(test_edges[['FromNode', 'ToNode', 'y']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
